#!/usr/bin/perl												#!/usr/bin/perl												
use strict;												use strict;												
use FindBin;												use FindBin;												
use lib "$FindBin::Bin/Parallel-ForkManager-0.7.9/lib";												use lib "$FindBin::Bin/Parallel-ForkManager-0.7.9/lib";												
use Parallel::ForkManager;												use Parallel::ForkManager;												
use List::MoreUtils 'pairwise';#to add arrays of same size together by element												use List::MoreUtils 'pairwise';#to add arrays of same size together by element												
=head												=head												
This script is a wrapper for annovar and its submission to the grid												This script is a wrapper for annovar and its submission to the grid												
outputs all the necessary files for grid 												outputs all the necessary files for grid 												
																								
You can specify a config file so that you can control your annovar arguments,												You can specify a config file so that you can control your annovar arguments,												
but mostly it works as is.												but mostly it works as is.												
v2.0 Add batching for parallelization												v2.0 Add batching for parallelization												
	ForkManager pm used for parallelization of the batch mode (-b)													ForkManager pm used for parallelization of the batch mode (-b)												
v2.1 Corrected for user specified -g and running on tork												v2.1 Corrected for user specified -g and running on tork												
	fixed call to annotate_variation.pl so it uses $bin and not hard-coded full path.													fixed call to annotate_variation.pl so it uses $bin and not hard-coded full path.												
	automatically batches data (-b is no longer valid)													automatically batches data (-b is no longer valid)												
v3.0 error handling for when batch(es) fail.  need to alert user of internal error and that t												v3.0 error handling for when batch(es) fail.  need to alert user of internal error and that t												
	--diagnose fail type and rerun? (planning)													--diagnose fail type and rerun? (planning)												
=cut												=cut												
if ( $ENV{'HOST'}=~/tork/i && $#ARGV>-1 && join("",@ARGV)!~/\-g/){												if ( $ENV{'HOST'}=~/tork/i && $#ARGV>-1 && join("",@ARGV)!~/\-g/){												
	#do not run CPU intensive jobs on tork													#do not run CPU intensive jobs on tork												
	my $dir=`pwd`;chomp $dir;$dir=`basename $dir`;chomp $dir;													my $dir=`pwd`;chomp $dir;$dir=`basename $dir`;chomp $dir;												
	open (MASTER, ">PBS.MASTER") or die "cannot open PBS.MASTER for writing\n";													open (MASTER, ">PBS.MASTER") or die "cannot open PBS.MASTER for writing\n";												
	print MASTER "#!/bin/sh\n#PBS -j oe -l arch=linux-x86_64,pvmem=2GB,mem=2GB,ncpus=2 -m													print MASTER "#!/bin/sh\n#PBS -j oe -l arch=linux-x86_64,pvmem=2GB,mem=2GB,ncpus=2 -m												
	print MASTER "cd ".`pwd`;													print MASTER "cd ".`pwd`;												
	print MASTER "perl $0 ".join (" ",@ARGV)." -g -T 2 \n"; 											      |		print MASTER "perl $0 ".join (" ",@ARGV)." -T 2\n"; 												
	close MASTER;													close MASTER;												
	exec ("qsub -q small -N PBS_$dir PBS.MASTER\n");											      |		exec ("qsub -q grande -N PBS_$dir PBS.MASTER\n");												
	exit;													exit;												
}else{												}else{												
	print "$0 ".join (" ",@ARGV)."\n";													print "$0 ".join (" ",@ARGV)."\n";												
}												}												
use Getopt::Std;												use Getopt::Std;												
use Data::Dumper;												use Data::Dumper;												
use FindBin;												use FindBin;												
use Tie::File;												use Tie::File;												
use lib "$FindBin::Bin/";												use lib "$FindBin::Bin/";												
use ABCC;												use ABCC;												
use vars qw($opt_E $opt_R $opt_A $opt_w $opt_z $opt_F $opt_x $opt_m $opt_H $opt_f $opt_a $opt											      |	use vars qw($opt_G $opt_w $opt_z $opt_F $opt_x $opt_m $opt_H $opt_f $opt_a $opt_o $opt_i $opt												
 getopts("f:o:c:d:i:T:t:l:B:k:p:m:F:A:rvRzsbcaehxgnHEINSw");											      |	 getopts("f:o:c:d:i:T:t:l:B:k:p:m:F:G:rvzsbcaehxgnHINSw");												
 umask(0000);												 umask(0000);												
my $usage=qq{												my $usage=qq{												
	$0 -i <input filename>													$0 -i <input filename>												
	[ONE OF THE FOLLOWING MUST BE SPECIFIED]													[ONE OF THE FOLLOWING MUST BE SPECIFIED]												
		-f <filename with databases to use>														-f <filename with databases to use>												
		-a <if specified, then it runs through all the databases for that organism in														-a <if specified, then it runs through all the databases for that organism in												
	[OPTIONAL]													[OPTIONAL]												
		-g <if specified, do not run on grid>														-g <if specified, do not run on grid>												
		-o <organism>  hg19														-o <organism>  hg19												
		-d <full path to database directory> 														-d <full path to database directory> 												
			DEFAULT: /SeqIdx/annovardb															DEFAULT: /SeqIdx/annovardb												
		-t <txt|vcf>														-t <txt|vcf>												
		-c <if specified then comments will not be included>														-c <if specified then comments will not be included>												
		-T <length of time before timeout> DEFAULT 1hr														-T <length of time before timeout> DEFAULT 1hr												
			in units of hours															in units of hours												
		-n <no run, just aggregate data>														-n <no run, just aggregate data>												
				-use the -k <num> option to specify the number of files that 																-use the -k <num> option to specify the number of files that 												
		-l <if aggregate was interrupted, use this to specify the line in the input f														-l <if aggregate was interrupted, use this to specify the line in the input f												
			automatically specifies -n option															automatically specifies -n option												
		-b <if specified, then all will run in parallel blocks>														-b <if specified, then all will run in parallel blocks>												
			ie. if you have a file of 1,000,000, this script will split the outpu															ie. if you have a file of 1,000,000, this script will split the outpu												
				It will also aggregate each of those files into one file at t																It will also aggregate each of those files into one file at t												
			You may specify -B option to specify the size of your block.  DEFAULT															You may specify -B option to specify the size of your block.  DEFAULT												
		-r <if specified, then it does NOT delete intermediate files>														-r <if specified, then it does NOT delete intermediate files>												
		-p <output filename> 														-p <output filename> 												
			#default: annovar_wrpr.output 															#default: annovar_wrpr.output 												
		-x <do not use strict>											      |			-x <use strict>												
			If possible, AVIA uses filter annot option to use the exact alleles t											      |				If possible uses filter annot option to use the exact alleles to anno												
			(filter instead of regionanno)															(filter instead of regionanno)												
			if specified, it will turn OFF this functionality and be more lenient											      <
		-m <column for name for indexing>  ##ADVANCED OPTION for AVIA pipeline, 0base														-m <column for name for indexing>  ##ADVANCED OPTION for AVIA pipeline, 0base												
			Only used if indexing occurs on the input database file.  															Only used if indexing occurs on the input database file.  												
		-F <annovar|database>											      |			-F <file with filtering order and instructions on which files to keep>												
			annovar - goes through the annovar filtering steps and returns only w											      |				input file looks like (one per line)												
			 1) mce_44way 2)segdup 3) All sites from 1000G 4)ceu/yri/jpt 5)dbsnp											      |					(1000g|hapmap|snp135|pp2|siftv63)\t(filtered|dropped|dropcuto												
			database - goes through the user-specified databases and returns only											      <
				-this option maybe be a subset or completely different than "											      <
		-z <if specified, then also runs query to get flanking sequences>														-z <if specified, then also runs query to get flanking sequences>												
		-A <allele frequency file>											      |			-G <specify a gene list in which to filter your output>												
		-R <rename headers and adds the filename to the beginning column>											      <
				#renames the headers of the output file to a more reader frie											      <
				#also adds the filename as a column at the beginning of the f											      <
	[CONDITIONAL]													[CONDITIONAL]												
		-w if specified, then it will generate web files;														-w if specified, then it will generate web files;												
		-k <number of files to split your input files>														-k <number of files to split your input files>												
			this is only used for -b option (batches).  Specifies the number of b															this is only used for -b option (batches).  Specifies the number of b												
		-s <do not split files>														-s <do not split files>												
		-N <do not run Annotation>														-N <do not run Annotation>												
		-v <if specified then the input file only has chr,start and stop positions, e														-v <if specified then the input file only has chr,start and stop positions, e												
		-S <if specified, sorts the input so that it *may* run faster if using indexe														-S <if specified, sorts the input so that it *may* run faster if using indexe												
																												
																												
};												};												
if ($opt_h || !defined $opt_i){print "$usage\n";exit;}												if ($opt_h || !defined $opt_i){print "$usage\n";exit;}												
$opt_o ||= 'hg19';												$opt_o ||= 'hg19';												
$opt_g ||= '0';												$opt_g ||= '0';												
$opt_B ||= 2_000_000;#in tests this seems to have the same runtime for batched vs non-batched												$opt_B ||= 2_000_000;#in tests this seems to have the same runtime for batched vs non-batched												
$opt_T = (defined $opt_T)? $opt_T*10000:60000;												$opt_T = (defined $opt_T)? $opt_T*10000:60000;												
if (defined $opt_b){												if (defined $opt_b){												
	$opt_T=60000;													$opt_T=60000;												
}												}												
if (!$opt_c){$opt_c=" --comment ";}else{ $opt_c='';}												if (!$opt_c){$opt_c=" --comment ";}else{ $opt_c='';}												
$opt_t ||= "txt";												$opt_t ||= "txt";												
my $out =(defined ($opt_p))?"$opt_p.annovar_wrpr":"$opt_i.annovar_wrpr";												my $out =(defined ($opt_p))?"$opt_p.annovar_wrpr":"$opt_i.annovar_wrpr";												
my %rank;#this is your rank of most important impact to least important												my %rank;#this is your rank of most important impact to least important												
my $orgdb="humandb";												my $orgdb="humandb";												
if ($opt_o!~/hg/i){$orgdb="mousedb";}												if ($opt_o!~/hg/i){$orgdb="mousedb";}												
$opt_d ||="/SeqIdx/annovardb/$orgdb";												$opt_d ||="/SeqIdx/annovardb/$orgdb";												
my $cwd=`pwd`;chomp $cwd;												my $cwd=`pwd`;chomp $cwd;												
if (defined $opt_l){$opt_n=1;print STDERR "[INFO]  You are specifying line $opt_l...using -n 												if (defined $opt_l){$opt_n=1;print STDERR "[INFO]  You are specifying line $opt_l...using -n 												
my $bin=`dirname $0`;chomp $bin;												my $bin=`dirname $0`;chomp $bin;												
my $annovar="perl $bin/annotate_variation_ABCC2.pl";											      |	my $annovar="perl $bin/annotate_variation_ABCC.pl";												
die "[ERROR] Your database directory $opt_d does not exist or is not a directory\n"  if ( (de												die "[ERROR] Your database directory $opt_d does not exist or is not a directory\n"  if ( (de												
die "[ERROR] Your -k $opt_k entry was invalid\n$usage" if (defined $opt_k && $opt_k!~/^\d+$/)												die "[ERROR] Your -k $opt_k entry was invalid\n$usage" if (defined $opt_k && $opt_k!~/^\d+$/)												
my @files;												my @files;												
my $MAX_PROCESSES=4;#max number of spans for a parallel process												my $MAX_PROCESSES=4;#max number of spans for a parallel process												
checkPBSAccess() if (!$opt_n);												checkPBSAccess() if (!$opt_n);												
											      >	my %flg;#keeps track of different flags												
											      >	my $convertible='FOO';#this is the tag that means that there was a conversion betwen two vers												
################## TESTING ###################												################## TESTING ###################												
#my $annovar_output="allANNOVAR.input.uniq.variant_function";											      |	#filtering												
#collapseANNOVAR($annovar_output);exit;											      |	my $filter_cmd;												
											      >	if (defined $opt_F){												
											      >		#this is for cascade filtering												
											      >		#order of file does not matter												
											      >		open (FILTERDB,"<$opt_F") or die "Cannot open filter database\n";												
											      >		my $dbdir='/SeqIdx/annovardb/'.$orgdb;												
											      >		#fill these in with the order from the web												
											      >		my %order=('hapmap_3.3'=>1,												
											      >			'1000gALL_sites_2012_04'=>2,												
											      >			'avsift'=>3,												
											      >			'ljb_pp2'=>4,												
											      >			'snp135'=>5												
											      >		);												
											      >		while (my $line=<FILTERDB>){												
											      >			chomp $line;my $threshold;												
											      >			next if ($line=~/^\s+$/);												
											      >			my ($dbfile,$keep,$cutoff)=split("\t",$line);												
											      >			if (exists $order{$dbfile}){												
											      >				$order{$dbfile}.=1;print "adding $dbfile from $line\n";												
											      >			}else{												
											      >				$order{$dbfile}='01';												
											      >			}												
											      >			if ($dbfile=~/(1000g|snp)/){												
											      >				$threshold='--maf_threshold';												
											      >			}elsif ($dbfile=~/avsift/){												
											      >				$threshold='--sift_threshold';												
											      >			}else{												
											      >				$threshold='--score_threshold';												
											      >			}												
											      >			if ($keep=~/(filtered|dropped)/){												
											      >				my $input;#we do this to build the query below for input; placeholder												
											      >				if ($keep=~/dropped/){												
											      >					$input="BAR";												
											      >				}else{												
											      >					$input="FOO";												
											      >				}												
											      >				$order{$dbfile}.="$annovar --buildver $opt_o --dbtype $dbfile --filte												
											      >			}elsif($keep=~/keepcutoff/){												
											      >				$order{$dbfile}.="$annovar --buildver $opt_o --dbtype $dbfile  --filt												
											      >			}elsif($keep=~/dropcutoff/){												
											      >				$order{$dbfile}.="$annovar --buildver $opt_o --dbtype $dbfile  --filt												
											      >			}												
											      >			#make sure the next file exists before inserting into next command												
											      >															
											      >		}												
											      >		my $input=$opt_i;												
											      >		foreach my $key (sort {$order{$a} cmp $order{$b} } keys %order){#most efficient way t												
											      >			$order{$key}=~s/^\d\d//g;$order{$key}=~s/(FOO|BAR)/$input/;												
											      >			my $dropped=$1;												
											      >			my $dbfile = ($order{$key}=~/\-\-dbtype\s(\S+)\s/)?$1:'';												
											      >			next if (!$dbfile);												
											      >			$filter_cmd.="$order{$key}";												
											      >			$input=($dropped=~/BAR/)?"$input.$opt_o\_$dbfile\_dropped":"$input.$opt_o\_$d												
											      >			print "$order{$key}\n";												
											      >		}												
											      >		my $id=printPBS("filter", '8',$filter_cmd);												
											      >		print STDERR "Monitoring filter queries $id\n";												
											      >		die "Could not submit $filter_cmd to the grid\n" if (!$id);												
											      >		my $notDone=monitor ("qstat | grep $id") ;												
											      >		if ($notDone){												
											      >			die "Could not filter your stuff\n";												
											      >		}												
											      >		print STDERR "Continuing with your data\n";												
											      >														
											      >		#now transfer your input file to your $opt_i to use												
											      >		$opt_i=$input;$flg{'cascade'}++;												
											      >	}												
############################################												############################################												
#open your input file and read in the databases you wish to search against												#open your input file and read in the databases you wish to search against												
if (defined $opt_f){												if (defined $opt_f){												
	open (INFILES,"<$opt_f") or die "Cannot open your input file($opt_f)\nTry specifying 													open (INFILES,"<$opt_f") or die "Cannot open your input file($opt_f)\nTry specifying 												
	@files=<INFILES>;													@files=<INFILES>;												
	close INFILES;													close INFILES;												
}elsif ($opt_a){												}elsif ($opt_a){												
	@files=`ls $opt_d/$opt_o*txt | grep -v refGene.txt`;													@files=`ls $opt_d/$opt_o*txt | grep -v refGene.txt`;												
}else{												}else{												
	@files=();#just runs gene anno													@files=();#just runs gene anno												
}												}												
push (@files, $opt_A) if (defined $opt_A && -e $opt_A);											      <
my $filemem=-s $opt_i;$filemem=int($filemem/100000000);#in GB												my $filemem=-s $opt_i;$filemem=int($filemem/100000000);#in GB												
#write on PBS job for each...												#write on PBS job for each...												
my $minmem=2+$filemem;#this is the min amount of memory needed to run a small ANNOVAR databas												my $minmem=2+$filemem;#this is the min amount of memory needed to run a small ANNOVAR databas												
my $jobs_qry='qstat | grep ';												my $jobs_qry='qstat | grep ';												
my @gids;#keeps track of the grid ids;												my @gids;#keeps track of the grid ids;												
my $use_strict=1;											      |	my $use_strict;												
$use_strict=(defined $opt_x)?0:1;											      |	$use_strict=(defined $opt_x)?1:0;												
#note the output from regulatory is always on a separate line												#note the output from regulatory is always on a separate line												
my $id;my $notDone=1;												my $id;my $notDone=1;												
#if (-e "$out.output"){ print STDERR "You have 10 seconds to kill this job before your existi												#if (-e "$out.output"){ print STDERR "You have 10 seconds to kill this job before your existi												
if (-e "DONE.$opt_i.anvr.wrpr"){unlink ("DONE.$opt_i.anvr.wrpr");}												if (-e "DONE.$opt_i.anvr.wrpr"){unlink ("DONE.$opt_i.anvr.wrpr");}												
my $ct=1;												my $ct=1;												
if ($opt_n){												if ($opt_n){												
	if ($opt_k){													if ($opt_k){												
		$ct=$opt_k+1;#we do this because we are  using 1 and not 0 as the first index														$ct=$opt_k+1;#we do this because we are  using 1 and not 0 as the first index												
	}else{ 													}else{ 												
		my $info=`wc $opt_i -l`;chomp $info;														my $info=`wc $opt_i -l`;chomp $info;												
		$ct=int($info/$opt_B)+1;														$ct=int($info/$opt_B)+1;												
	}													}												
}else{												}else{												
	if (!$opt_s){													if (!$opt_s){												
#			system ("rm $opt_i\\_* -f\n");												#			system ("rm $opt_i\\_* -f\n");												
		eval{														eval{												
			my $targetfile=$opt_i;															my $targetfile=$opt_i;												
			if ($opt_S){															if ($opt_S){												
				system ("sort $opt_i > tmp.sorted\n");																system ("sort $opt_i > tmp.sorted\n");												
				$targetfile="tmp.sorted";																$targetfile="tmp.sorted";												
			}															}												
			print "cmd:/usr/bin/split -l $opt_B -a 3 -d $targetfile $opt_i\\_ \n"															print "cmd:/usr/bin/split -l $opt_B -a 3 -d $targetfile $opt_i\\_ \n"												
			system (" /usr/bin/split -l $opt_B -a 3 -d $targetfile $opt_i\\_ \n")															system (" /usr/bin/split -l $opt_B -a 3 -d $targetfile $opt_i\\_ \n")												
		};														};												
		if ($?){														if ($?){												
			die "Could not split $opt_i into blocks!\n";															die "Could not split $opt_i into blocks!\n";												
		}														}												
		$ct=`ls  | grep -P '$opt_i\_\\d\\d\\d\$' | wc -l`;chomp $ct;														$ct=`ls  | grep -P '$opt_i\_\\d\\d\\d\$' | wc -l`;chomp $ct;												
	}elsif ($opt_k){													}elsif ($opt_k){												
		$ct=$opt_k+1;														$ct=$opt_k+1;												
	}else{													}else{												
		print "Running ls  | grep -P '$opt_i\_\\d\\d\\d\$' | wc -l\n";														print "Running ls  | grep -P '$opt_i\_\\d\\d\\d\$' | wc -l\n";												
		$ct=`ls  | grep -P '$opt_i\_\\d\\d\\d\$' | wc -l`;chomp $ct;														$ct=`ls  | grep -P '$opt_i\_\\d\\d\\d\$' | wc -l`;chomp $ct;												
	}													}												
	for (my $k=0;$k<$ct;$k++){													for (my $k=0;$k<$ct;$k++){												
		$k=sprintf("%03d",$k);														$k=sprintf("%03d",$k);												
		my $ensembl='';											      |			my $annot="$annovar --buildver $opt_o $opt_c --geneanno --keepline --relpos -												
		if ($opt_E){											      <
			$ensembl=" --dbtype ensgene ";#die "using ensembl\n";											      <
		}											      <
		my $annot="$annovar --buildver $opt_o $opt_c --geneanno $ensembl --keepline -											      <
		if ($opt_v){														if ($opt_v){												
			$annot=~s/\-\-relpos/\-\-relpos \-\-novar /;															$annot=~s/\-\-relpos/\-\-relpos \-\-novar /;												
		}else{											      <
#			$annot.=";perl $bin/../find_and_predict_NMD_indels.pl -i $opt_i\_$k.v											      <
		}														}												
		if (! -e "$opt_i\_$k.variant_function" && !$opt_n && !$opt_N){														if (! -e "$opt_i\_$k.variant_function" && !$opt_n && !$opt_N){												
			$id=printPBS("Annot\_$k",'8',$annot);															$id=printPBS("Annot\_$k",'8',$annot);												
		}														}												
	}													}												
}												}												
my $last_file="$opt_i\_".sprintf("%03d",$ct-1);#off by one bc we start at 0												my $last_file="$opt_i\_".sprintf("%03d",$ct-1);#off by one bc we start at 0												
my $lastfile_countline=`wc -l $last_file`;chomp $lastfile_countline;$lastfile_countline=~s/\s												my $lastfile_countline=`wc -l $last_file`;chomp $lastfile_countline;$lastfile_countline=~s/\s												
my $firstfile_headers_ct=`grep '^#' $opt_i\_000 | wc -l`;chomp $firstfile_headers_ct;$firstfi												my $firstfile_headers_ct=`grep '^#' $opt_i\_000 | wc -l`;chomp $firstfile_headers_ct;$firstfi												
print "There are $ct batches!!!\n";												print "There are $ct batches!!!\n";												
print "The last file ($last_file) has $lastfile_countline and $firstfile_headers_ct\n";												print "The last file ($last_file) has $lastfile_countline and $firstfile_headers_ct\n";												
#adjust the min memory and space requirements because you're now batching it												#adjust the min memory and space requirements because you're now batching it												
$filemem=-s "$opt_i\_000";$filemem=int($filemem/100000000);#in GB												$filemem=-s "$opt_i\_000";$filemem=int($filemem/100000000);#in GB												
#write on PBS job for each...												#write on PBS job for each...												
$minmem=2+$filemem;#this is the min amount of memory needed to run a small ANNOVAR database, 												$minmem=2+$filemem;#this is the min amount of memory needed to run a small ANNOVAR database, 												
if ($ct==1 && !$opt_S){												if ($ct==1 && !$opt_S){												
	unlink ("$opt_i\_000");													unlink ("$opt_i\_000");												
	system ("ln -s $opt_i $opt_i\_000\n");													system ("ln -s $opt_i $opt_i\_000\n");												
}												}												
my $fetch_script="$bin/../annofetch";print STDERR "Fetch script did not work..skipping ($fetc												my $fetch_script="$bin/../annofetch";print STDERR "Fetch script did not work..skipping ($fetc												
if ($opt_z && ! -e "$opt_i.flanks"){												if ($opt_z && ! -e "$opt_i.flanks"){												
	print STDERR "Running fetch script $fetch_script $opt_i $opt_i.flanks\n";													print STDERR "Running fetch script $fetch_script $opt_i $opt_i.flanks\n";												
	$id=printPBS("fetch",'2',"$fetch_script $opt_i $opt_i.flanks");													$id=printPBS("fetch",'2',"$fetch_script $opt_i $opt_i.flanks");												
	$opt_z="$opt_i.flanks";													$opt_z="$opt_i.flanks";												
}elsif ($opt_z && -e "$opt_i.flanks"){												}elsif ($opt_z && -e "$opt_i.flanks"){												
	$opt_z="$opt_i.flanks";													$opt_z="$opt_i.flanks";												
	print "$opt_z already exists..using it\n";													print "$opt_z already exists..using it\n";												
}												}												
my %db_size_hash;my $af;												my %db_size_hash;my $af;												
if (!$opt_n){#run the databases in ANNOVAR												if (!$opt_n){#run the databases in ANNOVAR												
	for (my $k=0;$k<$ct;$k++){#make pbs bat files for all of the databases													for (my $k=0;$k<$ct;$k++){#make pbs bat files for all of the databases												
		$k=sprintf("%03d",$k);														$k=sprintf("%03d",$k);												
		if ($#files>-1 && !$opt_n){#runs if there are files and opt_n is not specifie														if ($#files>-1 && !$opt_n){#runs if there are files and opt_n is not specifie												
			for (my $i=0;$i<=$#files;$i++){															for (my $i=0;$i<=$#files;$i++){												
				$files[$i]=~s/[\r\n]*$//;my ($db_dir,$db_file);											      |					chomp $files[$i];my ($db_dir,$db_file);												
				print STDERR "working on $files[$i]\n";																print STDERR "working on $files[$i]\n";												
				#find the size so that you can increase the memory on the gri																#find the size so that you can increase the memory on the gri												
				if ($files[$i]=~/^\//){#if not absolute path, make it the abs																if ($files[$i]=~/^\//){#if not absolute path, make it the abs												
					$db_dir=`dirname $files[$i]`;chomp $db_dir;																	$db_dir=`dirname $files[$i]`;chomp $db_dir;												
					$db_file=`basename $files[$i]`;chomp $db_file;																	$db_file=`basename $files[$i]`;chomp $db_file;												
				}else{																}else{												
					$db_dir=$opt_d;																	$db_dir=$opt_d;												
					$db_file=$files[$i];																	$db_file=$files[$i];												
					if (!-e "$opt_d/$files[$i]" && -e "./$files[$i]"){											      <
						$db_dir="./";											      <
					}											      <
				}											      <
				if ($files[$i]=~/\_af$/){											      <
					$af=$db_file ;											      <
					 next;											      <
				}																}												
											      >					$flg{'sift'}++ if ($files[$i]=~/sift/i);												
											      >					$af++ and next if ($files[$i]=~/\_af$/);												
											      >					$convertible='hg19_hg18converted.txt' and next if ($files[$i]												
				my ($int,$size);																my ($int,$size);												
				if (!exists $db_size_hash{"$db_dir/$db_file"}){																if (!exists $db_size_hash{"$db_dir/$db_file"}){												
					$size= -s "$db_dir/$db_file";																	$size= -s "$db_dir/$db_file";												
					$int=int($size/100000000);#in GB																	$int=int($size/100000000);#in GB												
					$int+=$minmem; 																	$int+=$minmem; 												
					$db_size_hash{"$db_dir/$db_file"}="$size,$int";																	$db_size_hash{"$db_dir/$db_file"}="$size,$int";												
				}else{																}else{												
					($size,$int)=split(",",$db_size_hash{"$db_dir/$db_fil																	($size,$int)=split(",",$db_size_hash{"$db_dir/$db_fil												
				}																}												
				if( ! -e "$db_dir/$db_file.idx" ){																if( ! -e "$db_dir/$db_file.idx" ){												
					#try to index the database before beginning																	#try to index the database before beginning												
					print "Trying to index file...$db_dir/$db_file\n";																	print "Trying to index file...$db_dir/$db_file\n";												
					my $success=_index($db_dir,$db_file,$opt_m);																	my $success=_index($db_dir,$db_file,$opt_m);												
				}																}												
				my $idxd=0;#indexed database exists																my $idxd=0;#indexed database exists												
				if ( -e "$db_dir/$db_file.idx"){#indexing available so you do																if ( -e "$db_dir/$db_file.idx"){#indexing available so you do												
					$int="8";$idxd=1;																	$int="8";$idxd=1;												
					$annovar .= " --batchsize 100k " if ($annovar!~/\-\-b																	$annovar .= " --batchsize 100k " if ($annovar!~/\-\-b												
				}																}												
				$db_file=~s/$opt_o\_//g;$db_file=~s/.txt//g;#$files[$i]=`base																$db_file=~s/$opt_o\_//g;$db_file=~s/.txt//g;#$files[$i]=`base												
				my $addon;																my $addon;												
				if ($opt_v){$addon=' --novar ';}#if your input file has no va																if ($opt_v){$addon=' --novar ';}#if your input file has no va												
				my $toDo="$annovar $opt_c --buildver $opt_o --dbtype $db_file																my $toDo="$annovar $opt_c --buildver $opt_o --dbtype $db_file												
																																
				print "PBS$k\_$i...($size)$int\n";																print "PBS$k\_$i...($size)$int\n";												
				if (($db_file=~/(1000g|snp1[23]\d|avsift|ljb|vcf|cg69|siftv63																if (($db_file=~/(1000g|snp1[23]\d|avsift|ljb|vcf|cg69|siftv63												
					$toDo="$annovar --buildver $opt_o --dbtype $db_file -																	$toDo="$annovar --buildver $opt_o --dbtype $db_file -												
					$int=8;#we do this because it is filter option and me																	$int=8;#we do this because it is filter option and me												
				}elsif ($db_file=~/cosmicdb/ && $use_strict){											      |					}elsif ($db_file=~/(hg19_.*hom_only|cosmicdb|hg19_CG-.*AllFre												
					$toDo="$annovar --buildver $opt_o --dbtype generic --											      <
				}elsif ($db_file=~/(hg19_.*hom_only|cosmicdb)/ &&  $use_stric											      <
					$toDo="$annovar --buildver $opt_o --dbtype generic --																	$toDo="$annovar --buildver $opt_o --dbtype generic --												
					$int=8																	$int=8												
				}elsif ($size > 1_000_000 && !$idxd){																}elsif ($size > 1_000_000 && !$idxd){												
				}																}												
				my $id=printPBS ("$k\_$i",$int,$toDo);																my $id=printPBS ("$k\_$i",$int,$toDo);												
			}#ends foreach file															}#ends foreach file												
		}#end if statement else should be $#files && $opt_n}														}#end if statement else should be $#files && $opt_n}												
#		}elsif ($#files && $opt_n){												#		}elsif ($#files && $opt_n){												
#			print "[INFO] Skipping running databases for ".join (",",@files)."\n"												#			print "[INFO] Skipping running databases for ".join (",",@files)."\n"												
#		}#ends if/else												#		}#ends if/else												
	}#end foreach k loop that sets up all the interim files with the database files;													}#end foreach k loop that sets up all the interim files with the database files;												
																								
	$notDone=1;													$notDone=1;												
	$notDone=monitor ($jobs_qry) unless ($jobs_qry !~/\d+/);													$notDone=monitor ($jobs_qry) unless ($jobs_qry !~/\d+/);												
	if ($opt_g){$notDone=0;}#not monitoring anymore													if ($opt_g){$notDone=0;}#not monitoring anymore												
	if ($notDone){													if ($notDone){												
		die "Your grid jobs exceeded the amount of time or did not get submitted corr														die "Your grid jobs exceeded the amount of time or did not get submitted corr												
	}													}												
}												}												
#check to see which ones ran properly												#check to see which ones ran properly												
# Max processes for parallel download ($MAX_PROCESSES)												# Max processes for parallel download ($MAX_PROCESSES)												
my %err;#logs errors												my %err;#logs errors												
my $pm = new Parallel::ForkManager($MAX_PROCESSES); 												my $pm = new Parallel::ForkManager($MAX_PROCESSES); 												
print "About to fork processes\n";												print "About to fork processes\n";												
my %donotaggregate;												my %donotaggregate;												
CHUNK: foreach (my $k=0;$k<$ct;$k++){												CHUNK: foreach (my $k=0;$k<$ct;$k++){												
	$k=sprintf("%03d",$k);													$k=sprintf("%03d",$k);												
	my @outputfiles;													my @outputfiles;												
	$pm->start and next; # do the fork													$pm->start and next; # do the fork												
	my $annovar_output="./$opt_i\_$k.variant_function";													my $annovar_output="./$opt_i\_$k.variant_function";												
	for (my $i=0;$i<=$#files;$i++){													for (my $i=0;$i<=$#files;$i++){												
		my $file;														my $file;												
		#locally run														#locally run												
		print "cannot be null...at line ".__LINE__ ."\n" and next if ($files[$i] eq '														print "cannot be null...at line ".__LINE__ ."\n" and next if ($files[$i] eq '												
		chomp $files[$i];														chomp $files[$i];												
		my ($dirname,$filename)=(`dirname $files[$i]`,`basename $files[$i]`);chomp $d														my ($dirname,$filename)=(`dirname $files[$i]`,`basename $files[$i]`);chomp $d												
		$filename=~s/\r//g;														$filename=~s/\r//g;												
		until ($filename!~/(.*)\.txt/){														until ($filename!~/(.*)\.txt/){												
			$filename=$1;															$filename=$1;												
		}														}												
		next if ($files[$i]=~/hg19_af/);											      |			$flg{'sift'}++ if ($files[$i]=~/sift/);												
											      >			$af++ and next if ($files[$i]=~/hg19_af$/);												
											      >			next if ($files[$i]=~/$convertible$/);												
		print "Running system: ls | grep $opt_i\_$k\.$filename\$ \n";														print "Running system: ls | grep $opt_i\_$k\.$filename\$ \n";												
		$file=`ls | grep $opt_i\_$k\.$filename\$`;chomp $file; 														$file=`ls | grep $opt_i\_$k\.$filename\$`;chomp $file; 												
		print "looking for $filename...found($file)\n";														print "looking for $filename...found($file)\n";												
																												
		if (!$file|| -z $file){														if (!$file|| -z $file){												
			print "Running system(2nd attempt): ls | grep  $opt_i\_$k\.$filename 											      |				print "Running system(2nd attempt): ls | grep  $opt_i\_$k\.$filename 												
			$file=`ls | grep  $opt_i\_$k\.$filename | grep -e filtered -e exact |											      |				$file=`ls | grep  $opt_i\_$k\.$filename | grep filtered`;chomp $file;												
			print "\tworking for ($file)\n";											      |				print "\tworking for $file\n";												
		}														}												
		if (!$file){															if (!$file){													
			$file="$opt_i\_$k.$filename";															$file="$opt_i\_$k.$filename";												
			print STDERR "======================\nCould not find a file for Datab															print STDERR "======================\nCould not find a file for Datab												
			my $tmpname=$filename;															my $tmpname=$filename;												
			if ($filename=~/(hg19\_|mm\d\_)(\w+)/){															if ($filename=~/(hg19\_|mm\d\_)(\w+)/){												
				$tmpname=$2;																$tmpname=$2;												
			}else{															}else{												
				die "$filename does notmatch regex\n";																die "$filename does notmatch regex\n";												
			}															}												
			my $success=_makeERRFile($file,$tmpname);															my $success=_makeERRFile($file,$tmpname);												
			if ($success){															if ($success){												
				$err{$annovar_output}.="Internal Error: Could not find the db																$err{$annovar_output}.="Internal Error: Could not find the db												
			}															}												
			#next CHUNK;															#next CHUNK;												
		}#CHUNKYMONKEY														}#CHUNKYMONKEY												
																												
		if ($file=~/filtered$/ && !-z $file){														if ($file=~/filtered$/ && !-z $file){												
			#sort it and then output only the score															#sort it and then output only the score												
			$file=_sortFilterFile($file);															$file=_sortFilterFile($file);												
		}														}												
		push (@outputfiles,$file);														push (@outputfiles,$file);												
	}													}												
	print STDERR  "[INFO] Finished collecting data on databases across ".sprintf ("%d",($													print STDERR  "[INFO] Finished collecting data on databases across ".sprintf ("%d",($												
																										
	if (-e "$annovar_output.collapsed" || $opt_N){													if (-e "$annovar_output.collapsed" || $opt_N){												
	}elsif (-e $annovar_output ){													}elsif (-e $annovar_output ){												
		if ($opt_l && -e "$annovar_output.collapsed"){#collapse the exonic and varian														if ($opt_l && -e "$annovar_output.collapsed"){#collapse the exonic and varian												
			collapseANNOVAR($annovar_output,$opt_l);															collapseANNOVAR($annovar_output,$opt_l);												
		}elsif ($opt_n && -e "$annovar_output.collapsed"){ #did not run annot and the														}elsif ($opt_n && -e "$annovar_output.collapsed"){ #did not run annot and the												
			#do nothing, hopefully this is your completed run															#do nothing, hopefully this is your completed run												
		}elsif ($opt_v && !-e "$annovar_output.collapsed"){														}elsif ($opt_v && !-e "$annovar_output.collapsed"){												
			open (COLLAPSED, ">$annovar_output.collapsed" ) or die "Cannot open $															open (COLLAPSED, ">$annovar_output.collapsed" ) or die "Cannot open $												
			my $annot_ver;											      |				print COLLAPSED join ("\t","#ANNOVAR annot","Gene","Rel pos to featur												
			if ($opt_E){											      <
				$annot_ver="Ensembl v.63";											      <
			}else{											      <
				$annot_ver="NCBI v37";											      <
			}											      <
			print COLLAPSED join ("\t","#ANNOVAR annot $annot_ver","Gene","Rel po											      <
			close COLLAPSED;															close COLLAPSED;												
			system ( "cat $annovar_output >>$annovar_output.collapsed\n");															system ( "cat $annovar_output >>$annovar_output.collapsed\n");												
		}else{#ran annot and collapse														}else{#ran annot and collapse												
			collapseANNOVAR($annovar_output,0);															collapseANNOVAR($annovar_output,0);												
			system ("rm $annovar_output\.*_variant_function -f \n") if (!$opt_r);															system ("rm $annovar_output\.*_variant_function -f \n") if (!$opt_r);												
		}														}												
	}else{													}else{												
		print STDERR "$annovar_output does not exist and -N and $annovar_output.colla														print STDERR "$annovar_output does not exist and -N and $annovar_output.colla												
		my $success=_makeERRFile("$annovar_output.collapsed",join ("\t",'ANNOVAR anno														my $success=_makeERRFile("$annovar_output.collapsed",join ("\t",'ANNOVAR anno												
		if ($success){														if ($success){												
			$err{$annovar_output}.="Internal Error: Could not find the db run for															$err{$annovar_output}.="Internal Error: Could not find the db run for												
		}														}												
	}													}												
																										
	print STDERR "[INFO] About to paste all samples for $k\n";													print STDERR "[INFO] About to paste all samples for $k\n";												
	if ($#outputfiles>-1){													if ($#outputfiles>-1){												
		eval{														eval{												
			my $cmd="paste ".join (" ",@outputfiles) ;															my $cmd="paste ".join (" ",@outputfiles) ;												
			if (!$opt_N){															if (!$opt_N){												
				$cmd.=" $annovar_output.collapsed > $out\_$k.output";																$cmd.=" $annovar_output.collapsed > $out\_$k.output";												
			}else{															}else{												
				$cmd.=" > $out\_$k.output";																$cmd.=" > $out\_$k.output";												
			}															}												
			print "$cmd\n";															print "$cmd\n";												
			system ("$cmd\n");															system ("$cmd\n");												
		};														};												
		if ($@){														if ($@){												
			die "could not join files together\n";															die "could not join files together\n";												
		}elsif (!$opt_r){														}elsif (!$opt_r){												
			eval{															eval{												
				system  ("rm $annovar_output.collapsed ". join (" ",@outputfi																system  ("rm $annovar_output.collapsed ". join (" ",@outputfi												
				system  ("rm PBS* -f ");																system  ("rm PBS* -f ");												
			};															};												
			if ($@){															if ($@){												
				warn "could not rm intermediate files\n";																warn "could not rm intermediate files\n";												
			}															}												
		}														}												
	}else{													}else{												
		eval{														eval{												
			system ("cp $annovar_output.collapsed $out\_$k.output\n");															system ("cp $annovar_output.collapsed $out\_$k.output\n");												
		};														};												
		if ($@){														if ($@){												
			die "could not cp $annovar_output.collapsed\n";															die "could not cp $annovar_output.collapsed\n";												
		}elsif (!$opt_r){														}elsif (!$opt_r){												
			system ("rm $annovar_output.collapsed\n");															system ("rm $annovar_output.collapsed\n");												
		}														}												
	}													}												
											      >		if (exists $flg{'sift'} && $flg{'sift'}){												
											      >			system ("perl $bin/../find_and_predict_NMD_indels.pl -i $out\_$k.output -o $o												
											      >			print "Running $bin/../find_and_predict_NMD_indels.pl -i $out\_$k.output -o $												
											      >			if (-e "$out\_$k.PredIndel" && !-z "$out\_$k.PredIndel"){												
											      >				eval{system ("mv $out\_$k.PredIndel $out\_$k.output\n");};												
											      >				if ($?){												
											      >					warn "could not move $out\_$k.PredIndel to $out\_$k.output(ok												
											      >				}												
											      >			}												
											      >		}												
	print STDERR "[INFO]  Done Pasting for $k\n";													print STDERR "[INFO]  Done Pasting for $k\n";												
	$pm->finish; # do the exit in the child process													$pm->finish; # do the exit in the child process												
}												}												
print STDERR "[INFO] Waiting for children processes to complete\n";												print STDERR "[INFO] Waiting for children processes to complete\n";												
$pm->wait_all_children;												$pm->wait_all_children;												
if (keys %err){												if (keys %err){												
	print "The following errors occurred during aggregation:\n";													print "The following errors occurred during aggregation:\n";												
	foreach my $errmsg (keys %err){													foreach my $errmsg (keys %err){												
		print "$errmsg\n";														print "$errmsg\n";												
	}													}												
}												}												
my @append=split("\n",`ls $out\_* | grep output\$`);												my @append=split("\n",`ls $out\_* | grep output\$`);												
print STDERR "($out.output)working on appending the following:\n\t".join("\n\t",@append)."\n"												print STDERR "($out.output)working on appending the following:\n\t".join("\n\t",@append)."\n"												
if ((-e "$out.output" && -z "$out.output") || !-e "$out.output"){												if ((-e "$out.output" && -z "$out.output") || !-e "$out.output"){												
	print STDERR "Working to get headers\n";													print STDERR "Working to get headers\n";												
	system ("grep '^#' -m 1 $append[0]>$out.output\n");													system ("grep '^#' -m 1 $append[0]>$out.output\n");												
	if ($opt_R){											      |		system ("cp $out.output headers.output\n");												
		system ("perl $bin/rename_headers.pl $out.output\n");											      <
	}											      <
	system ("cp $out.output $out.headers.output\n");											      <
}												}												
#die "Concatenating...". join (",",@append)."\n";;												#die "Concatenating...". join (",",@append)."\n";;												
my $err_flag;												my $err_flag;												
for (my $d=0;$d<=$#append;$d++){												for (my $d=0;$d<=$#append;$d++){												
	chomp $append[$d];													chomp $append[$d];												
	eval {													eval {												
		system ("grep -ve '^#' $append[$d] >>$out.output\n");														system ("grep -ve '^#' $append[$d] >>$out.output\n");												
		#time trial to see which method is quicker														#time trial to see which method is quicker												
		#system ("perl -pi -e '$_ = "" if ($. == 1);' $append[$d]\n");														#system ("perl -pi -e '$_ = "" if ($. == 1);' $append[$d]\n");												
		#system ("cat $append[$d] >> $out\n");														#system ("cat $append[$d] >> $out\n");												
	};													};												
	if ($?){													if ($?){												
		warn "could not append $append[$d] to $out.output\n\tRan:grep -ve '^#' $appen														warn "could not append $append[$d] to $out.output\n\tRan:grep -ve '^#' $appen												
		$err_flag.="\n\t[INTERNAL ERR] The number of input files does not equal outpu														$err_flag.="\n\t[INTERNAL ERR] The number of input files does not equal outpu												
	}else{													}else{												
		if (!$opt_r){														if (!$opt_r){												
			eval{															eval{												
				system ("rm $append[$d] -f \n") ;																system ("rm $append[$d] -f \n") ;												
			};															};												
			if ($?){															if ($?){												
				warn "could not remove intermediate file $append[$d] at LN"._																warn "could not remove intermediate file $append[$d] at LN"._												
			}															}												
		}														}												
	}													}												
}												}												
if ($opt_N){												if ($opt_N){												
	eval{													eval{												
		system ("echo '#Comments' > test.collapse;cat $opt_i>>test.collapse;paste $ou														system ("echo '#Comments' > test.collapse;cat $opt_i>>test.collapse;paste $ou												
	};													};												
	if ($?){													if ($?){												
		warn "Could not append the input file to the outputfile\n";														warn "Could not append the input file to the outputfile\n";												
	}													}												
}												}												
#cleanup($ct);											      |	cleanup($ct);												
																								
print STDERR "Done!\n";												print STDERR "Done!\n";												
											      >	$af=" ANNOVAR.input.hg19_af " if ($af);												
											      >	my $addon='';												
if ($opt_z && !$err_flag){												if ($opt_z && !$err_flag){												
	open (FLANK,"<$opt_z") or die "cannot open $opt_z\n";													open (FLANK,"<$opt_z") or die "cannot open $opt_z\n";												
	my @id=<FLANK>;													my @id=<FLANK>;												
	if ($id[0]=~/ERR/ && ( -e "cvrt2anvr.stderr.log" || `head $opt_i -n1`=~/^#/)){ 													if ($id[0]=~/ERR/ && ( -e "cvrt2anvr.stderr.log" || `head $opt_i -n1`=~/^#/)){ 												
		$id[0]=~s/ERR\s{0,}\n/#FlankingSequence\n/;														$id[0]=~s/ERR\s{0,}\n/#FlankingSequence\n/;												
	}else{													}else{												
		unshift(@id,"#FlankingSequence\n");														unshift(@id,"#FlankingSequence\n");												
	}													}												
	close FLANK;													close FLANK;												
	open (FLANKWRITE,">$opt_z.wHeaders") or die "cannot open $opt_z.wHeaders";													open (FLANKWRITE,">$opt_z.wHeaders") or die "cannot open $opt_z.wHeaders";												
	print FLANKWRITE join ("",@id);													print FLANKWRITE join ("",@id);												
	close FLANKWRITE; 													close FLANKWRITE; 												
											      >		$addon="$opt_z.wHeaders ";												
	system ("paste $opt_z.wHeaders $af $out.output> $out.output1;mv $out.output1 $out.out													system ("paste $opt_z.wHeaders $af $out.output> $out.output1;mv $out.output1 $out.out												
}elsif ($af){											      <
	system("paste $af $out.output> $out.output1;mv $out.output1 $out.output;\n");											      <
}												}												
											      >	if ($af){												
											      >		$addon=$af." ";												
											      >														
											      >	}												
											      >	if (-e "config.ini" && -e "$convertible" && !-z "$convertible"){												
											      >		$addon="$convertible ";												
											      >	}												
											      >	if ($addon){												
											      >		system("paste $addon $out.output> $out.output1;mv $out.output1 $out.output;\n");												
											      >	}												
											      >													
if ($err_flag){													if ($err_flag){													
	open (FINAL,">>$out.output") or die "Cannot open $out.output for appending error mess													open (FINAL,">>$out.output") or die "Cannot open $out.output for appending error mess												
	print FINAL "\n\nThe following errors occurred during processing:\n$err_flag";													print FINAL "\n\nThe following errors occurred during processing:\n$err_flag";												
	close FINAL;													close FINAL;												
}												}												
if (-e "config.ini" && `grep ^name_column_header=1 config.ini | wc -l`==1){											      |	if (`grep ^name_column_header=1 config.ini | wc -l`==1){												
	my ($input_header_name,$id);													my ($input_header_name,$id);												
	if ( $id=`grep ^file= config.ini`){											      |		if ($id=`grep ^file= config.ini`){												
		$id=`basename $id`;														$id=`basename $id`;												
		$id=~s/(^\d+\.|\.txt|\.vcf)//g;														$id=~s/(^\d+\.|\.txt|\.vcf)//g;												
	}elsif ( $id=`grep '^input_fullpath=' config.ini`){											      |		}elsif ($id=`grep '^input_fullpath=' config.ini`){												
		$id=`basename $id`;														$id=`basename $id`;												
		$id=~s/(\.txt|\.vcf)//g;														$id=~s/(\.txt|\.vcf)//g;												
	}else{											      <
		$id=$opt_i;											      <
		$id=~s/(hg19\_|\_Blood|\_tumor)//i;											      <
		$id=~s/(^\d+\.|\.txt|\.vcf)//g;											      <
	}													}												
	$id=~s/^(\d{14}\.)//g;													$id=~s/^(\d{14}\.)//g;												
	if ($id){													if ($id){												
		chomp $id;														chomp $id;												
		eval{														eval{												
#			system (" awk -F '^' '{print \"$id\",\$1}' OFS='\\t' $out.output >> .											      |				system (" awk -F '^' '{print \"$id\",\$1}' OFS='\\t' $out.output > .$												
			system ("awk -F '^' '{if ( NR==1 )  print \"#SampleName\",\$1  ; else											      <
		};														};												
		if ($@){														if ($@){												
			print STDERR "ERROR Could not append to the output your input filenam															print STDERR "ERROR Could not append to the output your input filenam												
		}														}												
		if ($opt_R && !-z ".$out.output"){											      <
			system ("mv .$out.output $out.output\n");											      <
		}											      <
	}													}												
}												}												
																								
system ("touch DONE.$opt_i.anvr.wrpr\n") if ((-s "$out.output") > 101);												system ("touch DONE.$opt_i.anvr.wrpr\n") if ((-s "$out.output") > 101);												
exit();												exit();												
sub _makeERRFile{												sub _makeERRFile{												
	my $xfn=shift;													my $xfn=shift;												
	my $xhead=shift;													my $xhead=shift;												
	my $xfct;													my $xfct;												
	if ($xfn=~/\_(\d{3})[\_\.]/){													if ($xfn=~/\_(\d{3})[\_\.]/){												
		$xfct=sprintf("%d",$1);														$xfct=sprintf("%d",$1);												
	}													}												
	my $flag;													my $flag;												
	if ($xfct==$ct-1){													if ($xfct==$ct-1){												
		$flag=$lastfile_countline-1;														$flag=$lastfile_countline-1;												
	}else{													}else{												
		$flag=$opt_B-1;#print $flag;														$flag=$opt_B-1;#print $flag;												
	}													}												
	if ($xfct==0){#subtract the headers starting with '#' too!													if ($xfct==0){#subtract the headers starting with '#' too!												
		$flag=$flag-$firstfile_headers_ct;														$flag=$flag-$firstfile_headers_ct;												
	}													}												
	print STDERR "Could not run  _makeERRFile for an empty filename\n" and return 0 if (!													print STDERR "Could not run  _makeERRFile for an empty filename\n" and return 0 if (!												
	print STDERR "Running _makeERRFile for $xfn($flag)\n";													print STDERR "Running _makeERRFile for $xfn($flag)\n";												
	open (ERRDFN,">$xfn") or die "Cannot open file for err\n";													open (ERRDFN,">$xfn") or die "Cannot open file for err\n";												
	print ERRDFN "#$xhead\n";													print ERRDFN "#$xhead\n";												
	for (my $i=0;$i<=$flag;$i++){													for (my $i=0;$i<=$flag;$i++){												
		print ERRDFN "INTERNAL ERR \n";														print ERRDFN "INTERNAL ERR \n";												
	}													}												
	close ERRDFN;													close ERRDFN;												
	return 1;													return 1;												
}												}												
sub cleanup{												sub cleanup{												
	my $ct=shift;													my $ct=shift;												
	return if (!$opt_r);													return if (!$opt_r);												
	#this subroutine moves the PBS jobs and intermediate files into a subdirectory													#this subroutine moves the PBS jobs and intermediate files into a subdirectory												
	my $dir=`date "+%Y%m%d"`;chomp $dir;													my $dir=`date "+%Y%m%d"`;chomp $dir;												
	system ("mkdir $dir\n");													system ("mkdir $dir\n");												
	system ("mv PBS*bat PBS*bat.o* *log *valid_input *notexon.input $dir/ \n"); 													system ("mv PBS*bat PBS*bat.o* *log *valid_input *notexon.input $dir/ \n"); 												
#	if ($ct>0){												#	if ($ct>0){												
#		for (my $i=0;$i<=$ct;$i++){												#		for (my $i=0;$i<=$ct;$i++){												
#			$i=sprintf("%03d",$i);												#			$i=sprintf("%03d",$i);												
#			system ("rm $opt_i\_$i $dir\n");												#			system ("rm $opt_i\_$i $dir\n");												
#		}												#		}												
#	}												#	}												
	return;													return;												
}												}												
sub monitor{												sub monitor{												
	my $targets=shift;													my $targets=shift;												
	if ($opt_g){													if ($opt_g){												
		return 0;														return 0;												
	}													}												
	my $timeout=`date "+%d%H%M%S"`;chomp $timeout;$timeout+=$opt_T;#1hour													my $timeout=`date "+%d%H%M%S"`;chomp $timeout;$timeout+=$opt_T;#1hour												
	my $done=0;													my $done=0;												
	until (`$targets` eq '' || $done){													until (`$targets` eq '' || $done){												
		sleep (60);														sleep (60);												
		my $curr_time=`date "+%d%H%M%S"`;chomp $curr_time;														my $curr_time=`date "+%d%H%M%S"`;chomp $curr_time;												
		if ( $curr_time>$timeout){$done=1;}														if ( $curr_time>$timeout){$done=1;}												
																										
	};													};												
	return $done;													return $done;												
}												}												
sub _populate_rank{												sub _populate_rank{												
	#rank the impacts													#rank the impacts												
	%rank=('3PRIME_UTR'=>3,													%rank=('3PRIME_UTR'=>3,												
'5PRIME_UTR'=>3,												'5PRIME_UTR'=>3,												
'NMD_TRANSCRIPT'=>1,												'NMD_TRANSCRIPT'=>1,												
'SPLICE_SITE'=>2,												'SPLICE_SITE'=>2,												
'CODING_UNKNOWN'=>1,												'CODING_UNKNOWN'=>1,												
'DOWNSTREAM'=>5,												'DOWNSTREAM'=>5,												
'ESSENTIAL_SPLICE_SITE'=>1,												'ESSENTIAL_SPLICE_SITE'=>1,												
'FRAMESHIFT_CODING'=>1,												'FRAMESHIFT_CODING'=>1,												
'INTERGENIC'=>5,												'INTERGENIC'=>5,												
'INTRONIC'=>4,												'INTRONIC'=>4,												
'NON_SYNONYMOUS_CODING'=>1,												'NON_SYNONYMOUS_CODING'=>1,												
'SYNONYMOUS_CODING'=>2,												'SYNONYMOUS_CODING'=>2,												
'REGULATORY_REGION'=>3,												'REGULATORY_REGION'=>3,												
'WITHIN_NON_CODING_GENE'=>2,												'WITHIN_NON_CODING_GENE'=>2,												
'STOP_GAINED'=>1,												'STOP_GAINED'=>1,												
'UPSTREAM'=>4												'UPSTREAM'=>4												
	);													);												
}												}												
sub printPBS{												sub printPBS{												
	my $name=shift; my $memsize=shift; my $cmd=shift;													my $name=shift; my $memsize=shift; my $cmd=shift;												
	open (OUT ,">$cwd/PBS.$opt_i.$name.bat") or die "Cannot open $cwd/PBS.$name.bat for w													open (OUT ,">$cwd/PBS.$opt_i.$name.bat") or die "Cannot open $cwd/PBS.$name.bat for w												
	print OUT  "#!/bin/sh\n";													print OUT  "#!/bin/sh\n";												
	print OUT  "#PBS -j oe -l arch=linux-x86_64,pvmem=$memsize\GB,mem=$memsize\GB\n";													print OUT  "#PBS -j oe -l arch=linux-x86_64,pvmem=$memsize\GB,mem=$memsize\GB\n";												
	print OUT  "cd $cwd\n";													print OUT  "cd $cwd\n";												
	print OUT  "$cmd \n";													print OUT  "$cmd \n";												
	close OUT ;													close OUT ;												
	my $xid=' ';													my $xid=' ';												
	#launch the job and return the id													#launch the job and return the id												
	if (!$opt_g){													if (!$opt_g){												
		my $jobs=`qsub PBS.$opt_i.$name.bat`;														my $jobs=`qsub PBS.$opt_i.$name.bat`;												
		chomp $jobs;														chomp $jobs;												
		if ($jobs=~/(\d+).abcc1.ncifcrf.gov/i){														if ($jobs=~/(\d+).abcc1.ncifcrf.gov/i){												
			$xid=$1;$jobs_qry.=" -e $xid ";															$xid=$1;$jobs_qry.=" -e $xid ";												
		}else{														}else{												
			print STDERR "[ERR] Could not submit PBS.$name.bat to the grid\n";															print STDERR "[ERR] Could not submit PBS.$name.bat to the grid\n";												
		}														}												
		push(@gids,$xid);														push(@gids,$xid);												
	}else{													}else{												
		eval{														eval{												
			system ("chmod +x PBS.$opt_i.$name.bat;./PBS.$opt_i.$name.bat\n");															system ("chmod +x PBS.$opt_i.$name.bat;./PBS.$opt_i.$name.bat\n");												
		};														};												
		if ($?){														if ($?){												
			warn "Error processing chmod and running command on PBS.$opt_i.$name.															warn "Error processing chmod and running command on PBS.$opt_i.$name.												
		}														}												
		push (@gids,'1');														push (@gids,'1');												
		$xid='1';														$xid='1';												
	}													}												
	return $xid;													return $xid;												
}												}												
sub checkPBSAccess{												sub checkPBSAccess{												
	if ($opt_g){#force local run													if ($opt_g){#force local run												
		$opt_g=1;return;														$opt_g=1;return;												
	}													}												
	print STDERR "checking PBS...\n";													print STDERR "checking PBS...\n";												
	eval {													eval {												
		system ("qstat\n");#checking if qstat errors out, if so , cannot run on grid														system ("qstat\n");#checking if qstat errors out, if so , cannot run on grid												
	};													};												
	if ($?){													if ($?){												
		$opt_g=1;														$opt_g=1;												
		print STDERR "[WARN] You cannot use the grid to run your jobs (system err)$?\														print STDERR "[WARN] You cannot use the grid to run your jobs (system err)$?\												
	}else{													}else{												
		print STDERR "[INFO] Submission to grid is allowed\n";														print STDERR "[INFO] Submission to grid is allowed\n";												
	}													}												
	return;													return;												
}											      \	}												
